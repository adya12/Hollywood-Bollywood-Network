# -*- coding: utf-8 -*-
"""networks project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16SbgjF_sKWzNImDKpUFMYE-PWiGzNV3i

# **Milestone 1: Data Loading & Cleaning**
"""

import pandas as pd

# --- Load dataset ---
file_path = "Movies_cleaned.csv"  # update path if needed
df = pd.read_csv(file_path, engine='python', on_bad_lines='skip', encoding='utf-8')
print("Initial dataset shape:", df.shape)
display(df.head())

# --- Basic cleaning ---

# Convert release_date to year
if 'release_date' in df.columns:
    df['year'] = pd.to_datetime(df['release_date'], errors='coerce').dt.year

# Drop rows without Cast info
df = df.dropna(subset=['Cast'])
df['Cast'] = df['Cast'].apply(lambda x: [a.strip() for a in str(x).split(',') if a.strip() != ""])

# Normalize original_language
df['original_language'] = df['original_language'].astype(str).str.lower().str.strip()

# Create Industry column
def classify_industry(lang):
    if 'hi' in lang:
        return 'Bollywood'
    elif 'en' in lang:
        return 'Hollywood'
    else:
        return None

df['Industry'] = df['original_language'].apply(classify_industry)

# Drop rows without Industry
df = df.dropna(subset=['Industry'])

# Check counts
print("Movie counts by Industry:")
print(df['Industry'].value_counts())
display(df.head())

"""#**Milestone 2: Hollywood‚ÄìBollywood Bipartite Network Construction & Analysis**"""

import networkx as nx
from tqdm import tqdm

# Split dataset using original_language or Industry
hollywood_movies = df[df['original_language'] == 'en']
bollywood_movies = df[df['original_language'] == 'hi']

print("Hollywood movies count:", len(hollywood_movies))
print("Bollywood movies count:", len(bollywood_movies))

# ---- Bipartite Graph ----
B = nx.Graph()

# Add movie nodes
B.add_nodes_from(hollywood_movies['Title'], bipartite=0)
B.add_nodes_from(bollywood_movies['Title'], bipartite=1)

# Add edges based on shared genres
for _, h_row in tqdm(hollywood_movies.iterrows(), total=len(hollywood_movies), desc="Connecting Movies"):
    for _, b_row in bollywood_movies.iterrows():
        if pd.notna(h_row['genres']) and pd.notna(b_row['genres']):
            h_genres = [g.strip().lower() for g in h_row['genres'].split(',')]
            b_genres = [g.strip().lower() for g in b_row['genres'].split(',')]
            if any(g in b_genres for g in h_genres):
                B.add_edge(h_row['Title'], b_row['Title'], relation='shared_genre')

print("Total nodes in bipartite graph:", B.number_of_nodes())
print("Total edges in bipartite graph:", B.number_of_edges())

print("Density:", nx.density(B))
print("Connected components:", nx.number_connected_components(B))

# Average degree
avg_degree = sum(dict(B.degree()).values()) / len(B)
print("Average degree:", avg_degree)

"""The constructed bipartite graph connecting Hollywood and Bollywood movies based on shared genres reveals a highly interconnected network. The graph‚Äôs density of 0.195 indicates a moderately dense structure, meaning that roughly 19.5% of all possible connections between Hollywood and Bollywood movies actually exist. This is quite high for a network of over 3,000 nodes, suggesting significant genre overlap between the two industries. The presence of only one connected component shows that the network is fully connected ‚Äî every movie in the dataset is indirectly linked to every other movie through shared genre relationships. In other words, there are no isolated clusters or disconnected genre groups; all movies participate in a single unified ecosystem. The average degree of approximately 657 implies that, on average, each movie shares genres with more than six hundred others across industries. This reflects a strong thematic alignment between Hollywood and Bollywood productions, where common genres like drama, action, and romance likely serve as bridges linking films from both industries. Overall, the network highlights a rich tapestry of cross-industry genre relationships, underscoring how closely the two cinematic worlds are connected in terms of storytelling themes and audience appeal.



"""

degree_dict = dict(B.degree())
top_connected = sorted(degree_dict.items(), key=lambda x: x[1], reverse=True)[:10]
print("Top 10 most connected movies:")
for title, degree in top_connected:
    print(f"{title}: {degree} connections")

"""The degree centrality analysis identifies Bollywood films such as Laal Rang, Judgementall Hai Kya, and Kaalakaandi as the most connected nodes within the Hollywood‚ÄìBollywood bipartite network. Each of these movies shares genre similarities with over 2,100 other films, highlighting their strong thematic versatility and widespread overlap across both industries. Many of these top-connected titles are multi-genre productions‚Äîcombining elements of drama, crime, comedy, or thriller‚Äîwhich enables them to link with a broad spectrum of Hollywood movies. This high degree of connectivity suggests that these films occupy a central position in the network, acting as bridges that link diverse genre clusters together. Interestingly, the dominance of Bollywood titles among the top nodes implies that Bollywood films tend to span multiple genres more frequently than their Hollywood counterparts, allowing them to connect widely across the shared-genre space. Overall, these highly connected movies represent key thematic hubs that help integrate the two industries into one cohesive cinematic network."""

hollywood_nodes = {n for n, d in B.nodes(data=True) if d.get('bipartite') == 0}
bollywood_nodes = set(B) - hollywood_nodes

hollywood_avg_deg = sum(B.degree(n) for n in hollywood_nodes) / len(hollywood_nodes)
bollywood_avg_deg = sum(B.degree(n) for n in bollywood_nodes) / len(bollywood_nodes)

print(f"Average connections per Hollywood movie: {hollywood_avg_deg:.2f}")
print(f"Average connections per Bollywood movie: {bollywood_avg_deg:.2f}")

"""On average, each Hollywood movie shares genres with about 440 other films, while each Bollywood movie connects to roughly 1,295 titles across the network. This means that Bollywood films tend to have nearly three times more cross-genre connections than their Hollywood counterparts. Such a pattern suggests that Bollywood movies often blend multiple genres‚Äîsuch as drama, romance, comedy, and action‚Äîwithin a single production, making them more versatile and more likely to overlap with a wide range of Hollywood films. In contrast, Hollywood productions appear somewhat more genre-focused, typically adhering to specific categories or tones. Overall, this disparity highlights Bollywood‚Äôs strong multi-genre storytelling tradition and its broader thematic reach within the global cinematic landscape.

# **Milestone 3: Actor‚ÄìMovie Bipartite Network Construction**
"""

import pandas as pd
import networkx as nx
from tqdm import tqdm

# Assuming you already have your cleaned dataframe from Milestone 1
movies = df.copy()

# Ensure 'original_language' is lowercase and standardized
movies['original_language'] = movies['original_language'].str.lower()

# Split dataset into Hollywood and Bollywood
hollywood_df = movies[movies['original_language'] == 'en']
bollywood_df = movies[movies['original_language'] == 'hi']

print("Hollywood movies:", len(hollywood_df))
print("Bollywood movies:", len(bollywood_df))

# Function to build an Actor‚ÄìMovie bipartite graph
def build_actor_movie_graph(sub_df, industry_name):
    """
    Create a bipartite graph where:
      - Movie nodes are one set (bipartite=0)
      - Actor nodes are another set (bipartite=1)
    """
    B = nx.Graph()

    # Add movie nodes
    B.add_nodes_from(sub_df['Title'], bipartite=0, type='movie')

    # Iterate through each movie and add actor connections
    for _, row in tqdm(sub_df.iterrows(), total=len(sub_df), desc=f"Building {industry_name} Graph"):
        movie = row['Title']
        cast_list = row['Cast']

        # Skip if Cast is missing or not a list
        if not isinstance(cast_list, list):
            continue

        for actor in cast_list:
            actor = actor.strip()
            if actor == "":
                continue

            # Add actor node if not already added
            if not B.has_node(actor):
                B.add_node(actor, bipartite=1, type='actor')

            # Add edge between actor and movie
            B.add_edge(actor, movie)

    print(f"\nüìΩÔ∏è {industry_name} Bipartite Graph Summary:")
    print(f"  ‚û§ Total nodes: {B.number_of_nodes()}")
    print(f"  ‚û§ Total edges: {B.number_of_edges()}")
    print(f"  ‚û§ Movies: {len(sub_df)}")
    print(f"  ‚û§ Actors: {len([n for n, d in B.nodes(data=True) if d['type'] == 'actor'])}")

    return B

# Build separate graphs for each industry
B_hollywood = build_actor_movie_graph(hollywood_df, "Hollywood")
B_bollywood = build_actor_movie_graph(bollywood_df, "Bollywood")

# Compute average cast size per movie and average movies per actor

def compute_basic_stats(B):
    movie_nodes = [n for n, d in B.nodes(data=True) if d['type'] == 'movie']
    actor_nodes = [n for n, d in B.nodes(data=True) if d['type'] == 'actor']

    avg_cast_size = sum(B.degree(m) for m in movie_nodes) / len(movie_nodes)
    avg_movies_per_actor = sum(B.degree(a) for a in actor_nodes) / len(actor_nodes)

    return avg_cast_size, avg_movies_per_actor

hollywood_cast, hollywood_actor = compute_basic_stats(B_hollywood)
bollywood_cast, bollywood_actor = compute_basic_stats(B_bollywood)

print("\n Actor‚ÄìMovie Network Summary:")
print(f"Hollywood ‚Üí Avg cast size: {hollywood_cast:.2f}, Avg movies per actor: {hollywood_actor:.2f}")
print(f"Bollywood ‚Üí Avg cast size: {bollywood_cast:.2f}, Avg movies per actor: {bollywood_actor:.2f}")

"""The Hollywood network consists of 2,508 movies and 8,215 actors, connected by 19,437 actor‚Äìmovie links, reflecting moderately large casts with an average of 7.75 actors per movie. On the other hand, the Bollywood network comprises 852 movies and 1,553 actors with 3,576 connections, indicating smaller cast sizes averaging 4.20 actors per movie. Despite the difference in network size, the average number of movies per actor is similar in both industries‚Äî2.37 for Hollywood and 2.30 for Bollywood‚Äîsuggesting that actors in both contexts tend to participate in a comparable number of films. The contrast in cast sizes implies that Hollywood productions involve broader collaboration across more actors per movie, while Bollywood appears to foster more repeated collaborations among a smaller group of actors. These bipartite networks provide a foundation for projecting actor‚Äìactor collaboration networks, which will enable a deeper analysis of co-starring patterns, network structure, and potential differences in collaboration culture between the two industries.

# **Milestone 4 ‚Äî Temporal Actor‚ÄìActor Collaboration Network Analysis**
"""

import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt
from collections import defaultdict

# --- Data Preparation ---
df = df.dropna(subset=['Cast', 'release_date', 'original_language'])
df['release_year'] = df['release_date'].astype(int)
df['original_language'] = df['original_language'].astype(str).str.lower().str.strip()

edges = []
for _, row in df.iterrows():
    actors = [a.strip() for a in row['Cast']]
    for actor in actors:
        edges.append((actor, row['Title'], row['release_year'], row['original_language']))
edges_df = pd.DataFrame(edges, columns=['actor', 'movie', 'year', 'original_language'])

# --- Temporal Analysis Functions ---
def sliding_windows(year_min, year_max, window=5):
    start = year_min
    while start + window - 1 <= year_max:
        yield (start, start + window - 1)
        start += 1

def build_actor_collab_graph(edgelist, lang_code, year_start, year_end):
    filtered = edgelist[
        (edgelist['original_language'] == lang_code) &
        (edgelist['year'] >= year_start) &
        (edgelist['year'] <= year_end)
    ]
    B = nx.Graph()
    B.add_nodes_from(filtered['actor'].unique(), bipartite='actors')
    B.add_nodes_from(filtered['movie'].unique(), bipartite='movies')
    B.add_edges_from([(row['actor'], row['movie']) for idx, row in filtered.iterrows()])
    actors = set(n for n, d in B.nodes(data=True) if d['bipartite'] == 'actors')
    G = nx.bipartite.weighted_projected_graph(B, actors)
    return G

def compute_network_metrics(G):
    if len(G) == 0:
        return {'avg_degree': 0, 'clustering': 0, 'assortativity': None, 'giant_component_size': 0}
    degrees = [d for _, d in G.degree()]
    avg_degree = sum(degrees) / len(degrees) if degrees else 0
    clustering = nx.average_clustering(G)
    try:
        assortativity = nx.degree_assortativity_coefficient(G)
    except Exception:
        assortativity = None
    giant_comp = max(nx.connected_components(G), key=len) if len(G) > 0 else []
    giant_component_size = len(giant_comp)
    return {
        'avg_degree': avg_degree,
        'clustering': clustering,
        'assortativity': assortativity,
        'giant_component_size': giant_component_size,
    }

year_min = df['release_year'].min()
year_max = df['release_year'].max()
metrics = {
    'Hollywood': defaultdict(list),
    'Bollywood': defaultdict(list),
}
windows = list(sliding_windows(year_min, year_max, window=5))
lang_label_map = {'en': 'Hollywood', 'hi': 'Bollywood'}

for lang_code, label in lang_label_map.items():
    for (start, end) in windows:
        G = build_actor_collab_graph(edges_df, lang_code, start, end)
        stats = compute_network_metrics(G)
        metrics[label]['window_start'].append(start)
        metrics[label]['window_end'].append(end)
        for key in ['avg_degree', 'clustering', 'assortativity', 'giant_component_size']:
            metrics[label][key].append(stats[key])

# --- Updated Plots: One Figure per Industry, y-limits optional, Proper Cleanup ---
def plot_metrics(metrics, label):
    plt.figure(figsize=(12, 7))
    windows = [f"{s}-{e}" for s, e in zip(metrics[label]['window_start'], metrics[label]['window_end'])]
    x = range(len(windows))
    plt.plot(x, metrics[label]['avg_degree'], marker='o', label='Average Degree')
    plt.plot(x, metrics[label]['clustering'], marker='v', label='Clustering Coefficient')
    plt.plot(x, metrics[label]['giant_component_size'], marker='s', label='Giant Component Size')
    if all(a is not None for a in metrics[label]['assortativity']):
        plt.plot(x, metrics[label]['assortativity'], marker='^', label='Assortativity Coefficient')
    plt.xticks(x, windows, rotation=45)
    plt.xlabel('5-Year Sliding Window')
    plt.ylabel('Metric Value')
    plt.title(f'Temporal Trends of Actor Collaboration Network Metrics ({label})')
    plt.legend()
    plt.tight_layout()
    plt.show()
    plt.close()  # This prevents double axis or ghost figures

plot_metrics(metrics, 'Hollywood')

"""new"""

def plot_metrics(metrics, label):
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    windows = [f"{s}-{e}" for s, e in zip(metrics[label]['window_start'], metrics[label]['window_end'])]
    x = range(len(windows))

    # Average Degree
    axes[0, 0].plot(x, metrics[label]['avg_degree'], marker='o', color='blue')
    axes[0, 0].set_title('Average Degree')
    axes[0, 0].set_xticks(x[::5])  # Show every 5th tick
    axes[0, 0].set_xticklabels(windows[::5], rotation=45)
    axes[0, 0].grid(True, alpha=0.3)

    # Clustering Coefficient
    axes[0, 1].plot(x, metrics[label]['clustering'], marker='v', color='green')
    axes[0, 1].set_title('Clustering Coefficient')
    axes[0, 1].set_xticks(x[::5])
    axes[0, 1].set_xticklabels(windows[::5], rotation=45)
    axes[0, 1].grid(True, alpha=0.3)

    # Giant Component Size
    axes[1, 0].plot(x, metrics[label]['giant_component_size'], marker='s', color='red')
    axes[1, 0].set_title('Giant Component Size')
    axes[1, 0].set_xticks(x[::5])
    axes[1, 0].set_xticklabels(windows[::5], rotation=45)
    axes[1, 0].grid(True, alpha=0.3)

    # Assortativity Coefficient
    if all(a is not None for a in metrics[label]['assortativity']):
        axes[1, 1].plot(x, metrics[label]['assortativity'], marker='^', color='purple')
    axes[1, 1].set_title('Assortativity Coefficient')
    axes[1, 1].set_xticks(x[::5])
    axes[1, 1].set_xticklabels(windows[::5], rotation=45)
    axes[1, 1].grid(True, alpha=0.3)

    fig.suptitle(f'Temporal Trends - {label} Actor Collaboration Network', fontsize=16)
    plt.tight_layout()
    plt.show()
    plt.close()

plot_metrics(metrics, 'Hollywood')
plot_metrics(metrics, 'Bollywood')

"""The temporal actor collaboration network metrics for Hollywood reveal important trends about the structure and evolution of movie industry collaborations. The giant component size, which reflects the number of connected actors in the largest cluster, starts very high and then experiences a notable decline, stabilizing in later windows. This indicates that Hollywood's actor network was initially highly interconnected, possibly due to large ensemble casts or legacy data, but saw reduced connectivity in more recent years, before showing signs of recovery and stabilization. Both the average degree and clustering coefficient remain low and nearly flat over time, meaning actors typically co-star with only a few unique individuals in any five-year period, and tightly knit collaborative groups are rare. The assortativity coefficient, consistently slightly negative, shows that prominent, well-connected actors tend to collaborate with those on the periphery rather than forming exclusive clusters. Overall, these patterns suggest that Hollywood's actor network operates with broad reach and limited density, where collaborations are spread widely but are not concentrated in small, repetitive teams. The connectivity and mixing between established and emerging actors keep the industry network cohesive, yet prevent the formation of tight clusters, likely reflecting both casting practices and the diverse structure of movie productions over the last decade."""

plot_metrics(metrics, 'Bollywood')

"""The temporal actor collaboration network metrics for Bollywood reveal a stable and cohesive industry network over the past decade. The size of the giant component, representing the largest connected cluster of actors, remains consistently high‚Äîbetween 750 and 850 actors‚Äîacross all time windows, indicating strong interconnectedness and the preservation of an integrated core in Bollywood's collaboration landscape. Both the average degree and clustering coefficient remain low and steady, suggesting that most collaborations involve actors working with only a few unique partners within each five-year window, and that tightly knit groups or ensembles are rare. The assortativity coefficient holds close to zero, emphasizing a balanced mix where popular and less-connected actors interact without strong preferences for clustering exclusively among similar peers. Overall, these patterns reflect Bollywood's tendency to maintain a robust, stable community of collaborating actors, but with sparse, star-like connections rather than dense or repetitive team formations. The enduring size of the network's core, combined with minimal fluctuations in local connectivity measures, points to a resilient industry structure that efficiently integrates new talent while limiting concentrated clusters or recurring ensembles.

# **Milestone 5 ‚Äî Repeated Collaborations and Null Model Comparison**
"""

import pandas as pd
import networkx as nx
import numpy as np
from collections import defaultdict, Counter
import random

# --- Step 1: Identify observed repeated collaborations ---
def get_repeated_collaborations(edges_df, lang_code):
    # Build co-starring counts for each window (total or per temporal window as needed)
    filtered = edges_df[edges_df['original_language'] == lang_code]
    movies = filtered.groupby('movie')['actor'].apply(list)
    pair_counts = Counter()
    for cast in movies:
        for i in range(len(cast)):
            for j in range(i+1, len(cast)):
                # Unordered pair
                pair = tuple(sorted([cast[i], cast[j]]))
                pair_counts[pair] += 1
    repeated_pairs = {pair: count for pair, count in pair_counts.items() if count >= 2}
    return repeated_pairs

observed_pairs_hollywood = get_repeated_collaborations(edges_df, 'en')
observed_pairs_bollywood = get_repeated_collaborations(edges_df, 'hi')

print(f"Hollywood repeated pairs: {len(observed_pairs_hollywood)}")
print(f"Bollywood repeated pairs: {len(observed_pairs_bollywood)}")

# --- Step 2: Null model generation and simulation ---
def create_null_model(edges_df, lang_code, num_runs=100):
    filtered = edges_df[edges_df['original_language'] == lang_code]
    movies = filtered.groupby('movie')['actor'].apply(list)

    actor_list = list(filtered['actor'].unique())
    movie_sizes = movies.apply(len).tolist()

    null_pair_counts = []

    for run in range(num_runs):
        # Randomly assign actors to movies with original sizes, preserving actor degree
        random.shuffle(actor_list)
        synthetic_casts = []
        idx = 0
        for size in movie_sizes:
            chosen = random.sample(actor_list, size)
            synthetic_casts.append(chosen)
        # Count pairs
        sim_pair_counts = Counter()
        for cast in synthetic_casts:
            for i in range(len(cast)):
                for j in range(i+1, len(cast)):
                    pair = tuple(sorted([cast[i], cast[j]]))
                    sim_pair_counts[pair] += 1
        # Store pairs with ‚â•2 appearances
        repeated_sim = sum(1 for count in sim_pair_counts.values() if count >= 2)
        null_pair_counts.append(repeated_sim)
    return null_pair_counts

hollywood_null = create_null_model(edges_df, 'en', num_runs=100)
bollywood_null = create_null_model(edges_df, 'hi', num_runs=100)

# --- Step 3: Z-score computation for repeated collaborations ---
def compute_z_score(obs_count, null_counts):
    mean_null = np.mean(null_counts)
    std_null = np.std(null_counts)
    z = (obs_count - mean_null) / std_null if std_null > 0 else np.nan
    return z, mean_null, std_null

hollywood_obs_count = len(observed_pairs_hollywood)
bollywood_obs_count = len(observed_pairs_bollywood)

hz, hnull_mean, hnull_std = compute_z_score(hollywood_obs_count, hollywood_null)
bz, bnull_mean, bnull_std = compute_z_score(bollywood_obs_count, bollywood_null)

print(f"Hollywood: Observed={hollywood_obs_count}, Null Mean={hnull_mean:.2f}, Z-score={hz:.2f}")
print(f"Bollywood: Observed={bollywood_obs_count}, Null Mean={bnull_mean:.2f}, Z-score={bz:.2f}")

# --- Step 4: Insights & Comparison ---
if hz > 2:
    print("Hollywood has significantly more repeated collaborations than expected by chance.")
elif hz < -2:
    print("Hollywood has significantly fewer repeated collaborations than expected.")
else:
    print("Hollywood's repeated collaborations align with a random null expectation.")

if bz > 2:
    print("Bollywood has significantly more repeated collaborations than expected by chance.")
elif bz < -2:
    print("Bollywood has significantly fewer repeated collaborations than expected.")
else:
    print("Bollywood's repeated collaborations align with a random null expectation.")

# Additional: Inspect pairwise structure
most_common_hollywood = Counter(observed_pairs_hollywood).most_common(10)
most_common_bollywood = Counter(observed_pairs_bollywood).most_common(10)

print("Top Hollywood repeated pairs:", most_common_hollywood)
print("Top Bollywood repeated pairs:", most_common_bollywood)

"""The analysis of repeated collaborations in actor networks shows a striking pattern in both Hollywood and Bollywood. In Hollywood, there are 3,002 actor pairs who have co-starred in at least two movies together, while Bollywood records 215 such pairs. When compared against random null models that preserve each actor's participation frequency and typical movie sizes, these counts are vastly higher than what would be expected by chance. Specifically, the mean number of repeated pairs in Hollywood's null models is only about 179, resulting in a z-score of 220.77, indicating an extremely significant deviation from randomness. Similarly, Bollywood's observed count of 215 repeated collaborations far exceeds its null mean of approximately 24, giving a z-score of 39.34. This statistical evidence strongly suggests that both industries have a strong tendency for actors to work together repeatedly‚Äîfar more than just random assignment to casts would predict.

Moreover, this tendency is reflected in the most common actor pairs. For Hollywood, superstar collaborations such as Chris Evans and Scarlett Johansson or Adam Sandler and Kevin James appear up to six times together, highlighting the industry's preference for stable on-screen partnerships or franchise-driven repeated casting. In Bollywood, frequent collaborators include iconic pairs like Deepika Padukone and Ranveer Singh, Alia Bhatt and Varun Dhawan, and others, with each top pairing featuring together three to four times. These results confirm that both Hollywood and Bollywood maintain not only connected networks, but also core clusters of recurring partnerships that foster tightly knit professional circles and industry cliques. This repeated collaboration tendency is a key structural feature distinguishing real-world movie networks from random networks.

# **Milestone 6 ‚Äî Actor Career Trajectory and Centrality Analysis**
"""

import pandas as pd
import networkx as nx
from collections import defaultdict
from joblib import Parallel, delayed

# --- Data prep stays the same ---
df = df.dropna(subset=['Cast', 'release_date', 'original_language'])
df['release_year'] = df['release_date'].astype(int)
df['original_language'] = df['original_language'].astype(str).str.lower().str.strip()

edges = []
for _, row in df.iterrows():
    actors = [a.strip() for a in row['Cast']]
    for actor in actors:
        edges.append((actor, row['Title'], row['release_year'], row['original_language']))
edges_df = pd.DataFrame(edges, columns=['actor', 'movie', 'year', 'original_language'])

year_min, year_max = df['release_year'].min(), df['release_year'].max()

# --- Window function ---
def sliding_windows(year_min, year_max, window=5):
    for start in range(year_min, year_max - window + 2):
        yield (start, start + window - 1)

# --- Graph builder (cached subsets) ---
def build_actor_collab_graph(edgelist, lang_code, year_start, year_end):
    filtered = edgelist.query(
        "original_language == @lang_code and @year_start <= year <= @year_end"
    )

    if filtered.empty:
        return nx.Graph()

    # Bipartite graph
    B = nx.Graph()
    B.add_edges_from(zip(filtered['actor'], filtered['movie']))
    actors = filtered['actor'].unique()

    # Projection to actor-actor weighted graph
    G = nx.bipartite.weighted_projected_graph(B, actors)
    return G

# --- Approximate + light centralities ---
def compute_centralities(G, sample_k=100):
    if len(G) == 0:
        return {}, {}, {}

    degree = dict(G.degree())

    # Approximate betweenness with node sampling (much faster)
    betweenness = nx.betweenness_centrality(G, k=min(sample_k, len(G)), seed=42)

    # Closeness centrality is OK for small graphs, skip or approximate otherwise
    closeness = (
        nx.closeness_centrality(G) if len(G) < 2000 else {n: 0 for n in G.nodes()}
    )

    return degree, betweenness, closeness

# --- Parallel processing across windows + languages ---
def process_window(lang_code, label, start, end):
    G = build_actor_collab_graph(edges_df, lang_code, start, end)
    deg, betw, close = compute_centralities(G)
    result = defaultdict(lambda: defaultdict(list))
    for actor in G.nodes():
        result[actor]['degree'].append(deg.get(actor, 0))
        result[actor]['betweenness'].append(betw.get(actor, 0))
        result[actor]['closeness'].append(close.get(actor, 0))
    return label, result, (start, end)

# --- Run all in parallel ---
lang_label_map = {'en': 'Hollywood', 'hi': 'Bollywood'}
windows = list(sliding_windows(year_min, year_max))

results = {label: defaultdict(lambda: defaultdict(list)) for label in lang_label_map.values()}

tasks = [(lang_code, label, start, end)
         for lang_code, label in lang_label_map.items()
         for (start, end) in windows]

parallel_outputs = Parallel(n_jobs=-1, verbose=10)(
    delayed(process_window)(*args) for args in tasks
)

# --- Merge results ---
for label, res, win in parallel_outputs:
    for actor, metrics in res.items():
        for metric, vals in metrics.items():
            results[label][actor][metric].extend(vals)

def plot_actor_trajectory(actor_data, actor_name, centrality_label, industry_label):
    if actor_name not in actor_data:
        print(f"No data for {actor_name} in {industry_label}")
        return
    y_values = actor_data[actor_name][centrality_label]
    x_labels = [f"{start}-{end}" for start, end in windows[:len(y_values)]]
    plt.figure(figsize=(10,5))
    plt.plot(x_labels, y_values, marker='o')
    plt.xticks(rotation=45)
    plt.xlabel('5-Year Sliding Window')
    plt.ylabel(f'{centrality_label.capitalize()} Centrality')
    plt.title(f'{centrality_label.capitalize()} Trajectory: {actor_name} ({industry_label})')
    plt.tight_layout()
    plt.grid(True)
    plt.show()

# Bollywood example
plot_actor_trajectory(results['Bollywood'], 'Deepika Padukone', 'degree', 'Bollywood')

# Hollywood example
plot_actor_trajectory(results['Hollywood'], 'Robert Downey Jr.', 'degree', 'Hollywood')

"""The degree trajectory plots for Deepika Padukone (Bollywood) and Robert Downey Jr. (Hollywood) reveal distinct patterns in each actor‚Äôs evolving network prominence over time. For Deepika Padukone, degree centrality starts at a relatively high level in the early 2010s but shows a consistent decline across subsequent sliding windows, reaching its lowest point around 2016‚Äì2020 before stabilizing at a lower level. This trend suggests that while she was highly connected and collaborated with many co-stars early in the observed period, her network breadth contracted over time, possibly reflecting more selective collaborations or changes in her industry role.

Robert Downey Jr.‚Äôs trajectory also begins with high degree centrality, indicating a broad and active co-actor network in the early windows. However, while there is a general downward trend similar to Deepika Padukone, the decline is less steep, and there is a noticeable mid-period uptick around 2016‚Äì2020. This mid-period boost may reflect participation in ensemble casts or major franchise films that temporarily expanded his collaboration network. By the last window (2018‚Äì2022), his degree centrality drops more sharply, potentially aligning with a reduction in collaborative film projects or focusing on solo endeavors.

Overall, both trajectories illustrate how career stages and strategic project choices can lead to dynamic changes in an actor‚Äôs network position. High early-career centrality often reflects rapid industry engagement or rising stardom, while subsequent declines may indicate a transition to selective, high-profile roles or a shift in career focus. This reinforces the value of network analysis for understanding the interplay between collaboration patterns and career evolution in the film industry.
"""

import pandas as pd

def early_vs_career_success(results_dict, career_summary, centrality_label, first_n=1, last_n=1):
    """
    Compute early and late career average centrality scores and combine with career success measure.

    Parameters:
    - results_dict: Dict of actor ‚Üí metrics list (centrality values over time).
    - career_summary: Pandas Series mapping actor to a career success metric (popularity, movie count, etc).
    - centrality_label: String specifying which centrality metric to analyze (e.g., 'degree').
    - first_n: Number of earliest windows to average for early career centrality.
    - last_n: Number of latest windows to average for late career centrality.

    Returns:
    - DataFrame with columns ['actor', 'early_centrality', 'late_centrality', 'total_movies_or_popularity']
    """
    data = []
    for actor, vals in results_dict.items():
        centr_values = vals.get(centrality_label, [])
        if len(centr_values) >= first_n + last_n:
            early_avg = sum(centr_values[:first_n]) / first_n
            late_avg = sum(centr_values[-last_n:]) / last_n
            success_metric = career_summary.get(actor, 0)
            data.append((actor, early_avg, late_avg, success_metric))
    df = pd.DataFrame(data, columns=['actor', 'early_centrality', 'late_centrality', 'career_success'])
    return df



# Extract Bollywood movies with one main actor per row (e.g., the FIRST actor in 'Cast')
df_bollywood = df[df['original_language'] == 'hi'].copy()
df_bollywood['main_actor'] = df_bollywood['Cast'].apply(lambda x: x[0].strip() if isinstance(x, list) and x else None)

# If each (main actor, movie) combo should count, take the max popularity per actor (or mean, median, etc)
popularity_series = df_bollywood.groupby('main_actor')['popularity'].max()  # or use .mean()/.sum()

df_bollywood_centrality = early_vs_career_success(
    results['Bollywood'],
    popularity_series,
    centrality_label='degree'
)

plt.figure(figsize=(8, 6))
plt.scatter(df_bollywood_centrality['early_centrality'], df_bollywood_centrality['career_success'], alpha=0.6)
plt.xlabel('Early Career Degree Centrality')
plt.ylabel('Popularity')
plt.title('Bollywood: Early Centrality vs Popularity')
plt.grid(True)
plt.show()

"""This scatter plot examines the relationship between actors‚Äô early career degree centrality‚Äîan indicator of their network connectedness at the beginning of their careers‚Äîand their eventual popularity. Most data points are concentrated at the lower end of both axes, showing that the majority of actors in the dataset started with modest centrality and remained at a relatively low level of popularity. There are a few notable outliers, like a small number of actors who achieved exceptionally high popularity even when their early centrality was not among the highest, suggesting that while collaborative network position is important, other factors‚Äîsuch as individual performance, star power, or unique opportunities‚Äîcan play a decisive role in determining popularity.

Additionally, the broad spread and lack of a clear upward trend indicate that there is not a strict linear relationship between early network centrality and later popularity among Bollywood actors. Some with high early centrality do not necessarily rise to the highest popularity, while some achieve high popularity without unusually high centrality in the early phase. This pattern highlights the multifaceted nature of career success in the film industry: while early connectedness might provide opportunities and visibility, sustained popularity is likely affected by diverse factors including talent, public image, and market dynamics. Overall, the plot suggests that network metrics like early degree centrality are only one piece of a more complex puzzle shaping an actor's rise to stardom in Bollywood.
"""

# Extract Hollywood movies with one main actor per row (e.g., the FIRST actor in 'Cast')
df_hollywood = df[df['original_language'] == 'en'].copy()
df_hollywood['main_actor'] = df_hollywood['Cast'].apply(
    lambda x: x[0].strip() if isinstance(x, list) and x else None
)

# Use max popularity per main actor across all movies they appeared in
popularity_series_hollywood = df_hollywood.groupby('main_actor')['popularity'].max()

# Calculate early vs career centrality with this popularity outcome
df_hollywood_centrality = early_vs_career_success(
    results['Hollywood'],
    popularity_series_hollywood,
    centrality_label='degree'
)

# Scatter plot of early degree centrality vs popularity for Hollywood actors
plt.figure(figsize=(8, 6))
plt.scatter(df_hollywood_centrality['early_centrality'], df_hollywood_centrality['career_success'], alpha=0.6)
plt.xlabel('Early Career Degree Centrality')
plt.ylabel('Popularity')
plt.title('Hollywood: Early Centrality vs Popularity')
plt.grid(True)
plt.show()

"""This scatter plot displays the relationship between an actor‚Äôs early career degree centrality within the Hollywood collaboration network and their eventual popularity. The data reveals that the vast majority of Hollywood actors have both low early degree centrality and modest popularity, as evidenced by the dense cluster of points toward the lower left of the graph. However, there are a notable number of actors with high early centrality‚Äîsome exceeding 200‚Äîand similarly several actors with very high popularity scores, with a handful of outliers exhibiting extreme values above 600 and even 1200.

Despite these high-value outliers, the overall distribution displays considerable horizontal and vertical spread, and no strong upward trend. This suggests that while a handful of well-connected actors early in their careers do go on to achieve substantial popularity, high early centrality does not guarantee high popularity, nor is it a prerequisite‚Äîsome highly popular actors began with relatively low network centrality. The scattered appearance and prevalence of points across the popularity axis for a range of early centrality levels indicate that other factors, beyond early collaborative position, are highly influential in determining Hollywood career success.

Notably, compared to Bollywood, the Hollywood dataset features a broader range of both degree centrality and popularity, possibly reflecting a larger industry scale and greater variation in actor opportunities and career trajectories. In conclusion, while early network embeddedness may provide advantages or visibility, the Hollywood data reinforce the idea that popularity and long-term success are shaped by a complex interplay of network, talent, marketability, and strategic career choices.

# **Milestone 7 ‚Äî Cross-Industry Comparison and Visualization**
"""

import matplotlib.pyplot as plt
import pandas as pd
import networkx as nx
import numpy as np

# === 1. TEMPORAL TRENDS COMPARISON ===

# Function to compute average metrics over time
def avg_metric_over_time(results_dict, windows, metric_name):
    avg_metric = []
    for i in range(len(windows)):
        metric_values = []
        for actor, metrics in results_dict.items():
            values = metrics.get(metric_name, [])
            if len(values) > i:
                metric_values.append(values[i])
        avg_metric.append(sum(metric_values) / len(metric_values) if metric_values else 0)
    return avg_metric

window_labels = [f"{start}-{end}" for start, end in windows]

# 1.1 Average Degree Centrality Comparison
avg_deg_bollywood = avg_metric_over_time(results['Bollywood'], windows, 'degree')
avg_deg_hollywood = avg_metric_over_time(results['Hollywood'], windows, 'degree')

plt.figure(figsize=(12, 5))
plt.plot(window_labels, avg_deg_bollywood, marker='o', linewidth=2, label='Bollywood', color='#FF6B6B')
plt.plot(window_labels, avg_deg_hollywood, marker='s', linewidth=2, label='Hollywood', color='#4ECDC4')
plt.xticks(rotation=45)
plt.xlabel('5-Year Sliding Window', fontsize=11)
plt.ylabel('Average Degree Centrality', fontsize=11)
plt.title('Cross-Industry Comparison: Average Degree Centrality Over Time', fontsize=13, fontweight='bold')
plt.legend(fontsize=10)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

"""The cross-industry comparison of average degree centrality reveals distinct collaboration patterns between Hollywood and Bollywood. Hollywood consistently shows higher average degree centrality across all time windows, indicating that Hollywood actors typically have broader collaboration networks compared to their Bollywood counterparts. Hollywood shows a general declining trend initially and then increases over the observed period. However, for Bollywood, it is increasing steadily and then seems to stabilize towards the end. This pattern suggests that Hollywood's collaboration structure may be more dynamic and responsive to industry changes, while Bollywood demonstrates that it is deviating from a more consistent, tight-knit collaborative culture.

"""

# 1.2 Betweenness Centrality Comparison
avg_betw_bollywood = avg_metric_over_time(results['Bollywood'], windows, 'betweenness')
avg_betw_hollywood = avg_metric_over_time(results['Hollywood'], windows, 'betweenness')

plt.figure(figsize=(12, 5))
plt.plot(window_labels, avg_betw_bollywood, marker='o', linewidth=2, label='Bollywood', color='#FF6B6B')
plt.plot(window_labels, avg_betw_hollywood, marker='s', linewidth=2, label='Hollywood', color='#4ECDC4')
plt.xticks(rotation=45)
plt.xlabel('5-Year Sliding Window', fontsize=11)
plt.ylabel('Average Betweenness Centrality', fontsize=11)
plt.title('Cross-Industry Comparison: Average Betweenness Centrality Over Time', fontsize=13, fontweight='bold')
plt.legend(fontsize=10)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

"""Betweenness centrality measures how often actors serve as bridges between different parts of the collaboration network. The comparison shows that Bollywood actors consistently have higher average betweenness centrality than Hollywood actors across all time periods. This suggests that Bollywood's network structure features more critical intermediary positions, where certain actors play essential roles in connecting otherwise disconnected groups. In contrast, Hollywood's lower betweenness centrality indicates a more evenly distributed network where connections are less dependent on specific bridge actors. Both industries show relatively stable betweenness over time, with Bollywood exhibiting a slight increase in recent windows, potentially reflecting the emergence of key actors who increasingly bridge different collaborative clusters within the industry.

"""

# 1.3 Multi-Metric Comparison (Subplots)
avg_close_bollywood = avg_metric_over_time(results['Bollywood'], windows, 'closeness')
avg_close_hollywood = avg_metric_over_time(results['Hollywood'], windows, 'closeness')

fig, axes = plt.subplots(3, 1, figsize=(14, 12))

# Degree
axes[0].plot(window_labels, avg_deg_bollywood, marker='o', linewidth=2.5, label='Bollywood', color='#FF6B6B', markersize=8)
axes[0].plot(window_labels, avg_deg_hollywood, marker='s', linewidth=2.5, label='Hollywood', color='#4ECDC4', markersize=8)
axes[0].set_ylabel('Average Degree', fontsize=11, fontweight='bold')
axes[0].set_title('Temporal Comparison of Centrality Metrics Across Industries', fontsize=14, fontweight='bold')
axes[0].legend(fontsize=10)
axes[0].grid(True, alpha=0.3)
axes[0].tick_params(labelbottom=False)

# Betweenness
axes[1].plot(window_labels, avg_betw_bollywood, marker='o', linewidth=2.5, label='Bollywood', color='#FF6B6B', markersize=8)
axes[1].plot(window_labels, avg_betw_hollywood, marker='s', linewidth=2.5, label='Hollywood', color='#4ECDC4', markersize=8)
axes[1].set_ylabel('Average Betweenness', fontsize=11, fontweight='bold')
axes[1].legend(fontsize=10)
axes[1].grid(True, alpha=0.3)
axes[1].tick_params(labelbottom=False)

# Closeness
axes[2].plot(window_labels, avg_close_bollywood, marker='o', linewidth=2.5, label='Bollywood', color='#FF6B6B', markersize=8)
axes[2].plot(window_labels, avg_close_hollywood, marker='s', linewidth=2.5, label='Hollywood', color='#4ECDC4', markersize=8)
axes[2].set_xlabel('5-Year Sliding Window', fontsize=11, fontweight='bold')
axes[2].set_ylabel('Average Closeness', fontsize=11, fontweight='bold')
axes[2].legend(fontsize=10)
axes[2].grid(True, alpha=0.3)
axes[2].tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.show()

"""This comprehensive multi-metric comparison reveals nuanced differences in collaboration network structures between Hollywood and Bollywood. **Degree centrality** shows Hollywood consistently maintaining higher average values, indicating broader collaborative reach per actor. **Betweenness centrality** presents an opposite pattern‚ÄîBollywood actors demonstrate consistently higher values, suggesting their networks rely more heavily on key bridge actors to maintain connectivity between different clusters. This implies a more hierarchical or star-based collaboration structure in Bollywood compared to Hollywood's more distributed network. **Closeness centrality** shows Hollywood hovering near zero with minimal variation, indicating that the average path length between actors remains relatively similar across Hollywood.

The contrasting patterns between degree and betweenness centrality are particularly telling: Hollywood favors broad, distributed connections, while Bollywood's structure features tighter clusters connected through strategic intermediary actors.

"""

# === 2. EVOLUTION OF NETWORK===

# Select three time periods for comparison: Early, Mid, Late
snapshot_windows = [windows[0], windows[len(windows)//2], windows[-1]]
snapshot_labels = ['Early Period', 'Mid Period', 'Late Period']

print("Selected snapshot periods for visualization:")
for label, (start, end) in zip(snapshot_labels, snapshot_windows):
    print(f"{label}: {start}-{end}")

# Build networks for each snapshot period
def build_snapshot_graphs(lang_code, snapshot_windows):
    graphs = []
    for (start, end) in snapshot_windows:
        G = build_actor_collab_graph(edges_df, lang_code, start, end)
        graphs.append(G)
    return graphs

hollywood_snapshots = build_snapshot_graphs('en', snapshot_windows)
bollywood_snapshots = build_snapshot_graphs('hi', snapshot_windows)

# print("\nHollywood snapshot network sizes:")
# for i, G in enumerate(hollywood_snapshots):
#     print(f"  {snapshot_labels[i]}: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges")

# print("\nBollywood snapshot network sizes:")
# for i, G in enumerate(bollywood_snapshots):
#     print(f"  {snapshot_labels[i]}: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges")

# 2.1 Compare structural metrics across snapshots
def compute_snapshot_metrics(graphs, labels):
    metrics_df = []
    for i, G in enumerate(graphs):
        if len(G) > 0:
            density = nx.density(G)
            num_components = nx.number_connected_components(G)
            avg_degree = sum(dict(G.degree()).values()) / len(G) if len(G) > 0 else 0
            clustering = nx.average_clustering(G)

            # Giant component
            if num_components > 0:
                giant = max(nx.connected_components(G), key=len)
                giant_size = len(giant)
                giant_ratio = giant_size / len(G)
            else:
                giant_size = 0
                giant_ratio = 0

            metrics_df.append({
                'Period': labels[i],
                'Density': density,
                'Avg Degree': avg_degree,
                'Clustering': clustering,
                'Components': num_components,
                'Giant Component': giant_size,
                'Giant Ratio': giant_ratio
            })
    return pd.DataFrame(metrics_df)

hollywood_snapshot_metrics = compute_snapshot_metrics(hollywood_snapshots, snapshot_labels)
bollywood_snapshot_metrics = compute_snapshot_metrics(bollywood_snapshots, snapshot_labels)

print("\n=== Hollywood Network Evolution ===")
print(hollywood_snapshot_metrics.to_string(index=False))

print("\n=== Bollywood Network Evolution ===")
print(bollywood_snapshot_metrics.to_string(index=False))

# 2.2 Visual comparison of network evolution
fig, axes = plt.subplots(2, 3, figsize=(18, 10))
axes = axes.flatten()

periods = [label.split()[0] for label in snapshot_labels]  # ['Early', 'Mid', 'Late']

# Density
axes[0].bar(np.arange(len(periods)) - 0.2, hollywood_snapshot_metrics['Density'],
            width=0.4, label='Hollywood', color='#4ECDC4', alpha=0.8)
axes[0].bar(np.arange(len(periods)) + 0.2, bollywood_snapshot_metrics['Density'],
            width=0.4, label='Bollywood', color='#FF6B6B', alpha=0.8)
axes[0].set_xticks(np.arange(len(periods)))
axes[0].set_xticklabels(periods)
axes[0].set_ylabel('Density', fontweight='bold')
axes[0].set_title('Network Density Evolution', fontweight='bold')
axes[0].legend()
axes[0].grid(axis='y', alpha=0.3)

# Average Degree
axes[1].bar(np.arange(len(periods)) - 0.2, hollywood_snapshot_metrics['Avg Degree'],
            width=0.4, label='Hollywood', color='#4ECDC4', alpha=0.8)
axes[1].bar(np.arange(len(periods)) + 0.2, bollywood_snapshot_metrics['Avg Degree'],
            width=0.4, label='Bollywood', color='#FF6B6B', alpha=0.8)
axes[1].set_xticks(np.arange(len(periods)))
axes[1].set_xticklabels(periods)
axes[1].set_ylabel('Average Degree', fontweight='bold')
axes[1].set_title('Average Degree Evolution', fontweight='bold')
axes[1].legend()
axes[1].grid(axis='y', alpha=0.3)

# Clustering Coefficient
axes[2].bar(np.arange(len(periods)) - 0.2, hollywood_snapshot_metrics['Clustering'],
            width=0.4, label='Hollywood', color='#4ECDC4', alpha=0.8)
axes[2].bar(np.arange(len(periods)) + 0.2, bollywood_snapshot_metrics['Clustering'],
            width=0.4, label='Bollywood', color='#FF6B6B', alpha=0.8)
axes[2].set_xticks(np.arange(len(periods)))
axes[2].set_xticklabels(periods)
axes[2].set_ylabel('Clustering Coefficient', fontweight='bold')
axes[2].set_title('Clustering Evolution', fontweight='bold')
axes[2].legend()
axes[2].grid(axis='y', alpha=0.3)

# Giant Component Ratio
axes[3].bar(np.arange(len(periods)) - 0.2, hollywood_snapshot_metrics['Giant Ratio'],
            width=0.4, label='Hollywood', color='#4ECDC4', alpha=0.8)
axes[3].bar(np.arange(len(periods)) + 0.2, bollywood_snapshot_metrics['Giant Ratio'],
            width=0.4, label='Bollywood', color='#FF6B6B', alpha=0.8)
axes[3].set_xticks(np.arange(len(periods)))
axes[3].set_xticklabels(periods)
axes[3].set_ylabel('Giant Component Ratio', fontweight='bold')
axes[3].set_title('Network Connectivity Evolution', fontweight='bold')
axes[3].legend()
axes[3].grid(axis='y', alpha=0.3)

# Number of Components
axes[4].bar(np.arange(len(periods)) - 0.2, hollywood_snapshot_metrics['Components'],
            width=0.4, label='Hollywood', color='#4ECDC4', alpha=0.8)
axes[4].bar(np.arange(len(periods)) + 0.2, bollywood_snapshot_metrics['Components'],
            width=0.4, label='Bollywood', color='#FF6B6B', alpha=0.8)
axes[4].set_xticks(np.arange(len(periods)))
axes[4].set_xticklabels(periods)
axes[4].set_ylabel('Number of Components', fontweight='bold')
axes[4].set_title('Network Fragmentation Evolution', fontweight='bold')
axes[4].legend()
axes[4].grid(axis='y', alpha=0.3)

# Hide the unused 6th subplot
fig.delaxes(axes[5])

plt.suptitle('Cross-Industry Structural Evolution Comparison', fontsize=16, fontweight='bold', y=1.00)
plt.tight_layout()
plt.show()

"""The structural evolution comparison reveals fascinating differences in how Hollywood and Bollywood collaboration networks have transformed over time.  **Network density** reveals a striking contrast: Hollywood maintains very low density while Bollywood shows significantly higher density, indicating that Bollywood actors form more interconnected collaboration webs. **Average degree** shows that Hollywood actors maintain more co-star connections per capita. **Clustering coefficient** is quite high in both industries, indicating that actors who work with the same collaborators are very likely to have also worked together. This suggests tightly knit collaboration circles and the presence of overlapping teams, which is typical of social or co-acting networks derived from bipartite projections. **Giant component ratio** is extremely high in both industries across all periods, demonstrating robust connectivity‚Äînearly all actors belong to a single unified network. **Fragmentation** (number of components) shows Hollywood has more isolated components, likely due to its larger scale, while Bollywood maintains fewer, more cohesive clusters. Overall, these patterns suggest Hollywood operates as a broad, interconnected ecosystem with distributed collaborations, while Bollywood functions as a tighter, more centralized network with strategic bridge actors connecting different clusters.

"""

